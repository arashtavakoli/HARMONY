{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First thing is to plot the HR data this helps us see HR together with the change points for some visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for case study, just reading HR right hand\n",
    "\n",
    "import pandas as pd \n",
    "from tqdm import tqdm\n",
    "\n",
    "sensors = [\"HeartRateDatum\"]\n",
    "df_ultimate = []\n",
    "\n",
    "for sensor in sensors:\n",
    "    df_temp = pd.read_csv(\"C:/Users/Arsalan/Desktop/both hands and car/raw/\"+\"Smartwatch_\"+sensor+\".csv\",parse_dates=['Timestamp'])\n",
    "    start_date = \"2020-08-21T23:30:59.154+0000\"\n",
    "    end_date = \"2020-08-22T02:14:56.307+0000\"\n",
    "#     start_date = \"2020-08-23T15:16:11.508+0000\"\n",
    "#     end_date = \"2020-08-23T18:21:56.074+0000\"\n",
    "    mask = (df_temp['Timestamp'] > start_date) & (df_temp['Timestamp'] <= end_date)\n",
    "    df_temp = df_temp.loc[mask]\n",
    "    df_ultimate.append(df_temp)\n",
    "\n",
    "    \n",
    "df_final = df_ultimate[0]\n",
    "\n",
    "    \n",
    "    \n",
    "df_final = df_final.set_index(\"Timestamp\")\n",
    "df_final = df_final.groupby([\"DeviceId\"]).resample('1000L').mean().ffill().bfill()\n",
    "df_final = df_final.reset_index()\n",
    "\n",
    "#keep a copy to not rerun things\n",
    "hr_imu_data = df_final.copy()\n",
    "hr_imu_data = hr_imu_data.set_index(\"Timestamp\")\n",
    "hr_imu_data_left=hr_imu_data[hr_imu_data[\"DeviceId\"]==\"f60691a313420a4e\"]\n",
    "hr_imu_data_right=hr_imu_data[hr_imu_data[\"DeviceId\"]==\"39ca51c16b9ec429\"]\n",
    "\n",
    "#plottign HR change points for case study\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import wasserstein_distance\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "change_point_hr_included = pd.read_csv(\"change_point_hr_included.csv\")\n",
    "change_point_hr_included = change_point_hr_included.set_index(\"Timestamp\")\n",
    "fig1 = make_subplots(rows=3, cols=1, \n",
    "                    shared_xaxes=True,vertical_spacing =0.05)\n",
    "fig1.add_trace(go.Scatter(x=change_point_hr_included.index, y=change_point_hr_included[\"HR\"],name= \"HR\",yaxis='y2',line=dict(width=4,color='black')),row=1,col=1)\n",
    "fig1.add_trace(go.Scatter(x=change_point_hr_included.index, y=change_point_hr_included[\"HR _bcp_mean\"],name= \"HR - mean\",yaxis='y2',line=dict(width=4,color='blue')),row=2,col=1)\n",
    "fig1.add_trace(go.Scatter(x=change_point_hr_included.index, y=change_point_hr_included[\"HR _bcp_prob\"],name= \"BCP - probability\",line=dict(width=4,color='red')),row=3,col=1)\n",
    "\n",
    "fig1.update_layout(    \n",
    "    {    \n",
    "        'yaxis':{'dtick': 30,'title':\"<b>HR (bpm)\",'linecolor':'black'},\n",
    "        'yaxis2':{'dtick': 30,'title':\"<b>HR (bpm)\",'linecolor':'black'},\n",
    "        'yaxis3':{'range': [0, 1], 'dtick': 0.2,'title':'<b>Pr','linecolor':'black'},\n",
    "        'xaxis3':{'title':\"<b>Time\",'linecolor':'black'},\n",
    "        'height':600,\n",
    "        'width':1200,\n",
    "        'font':dict(size=14),\n",
    "        'paper_bgcolor':'rgba(0,0,0,0)',\n",
    "        'plot_bgcolor':'rgba(0,0,0,0)'\n",
    "    }\n",
    ")\n",
    "\n",
    "fig1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### Second part is to show how different change points are using other modalities of data\n",
    "1. Reading change points\n",
    "2. Reading all sources of wearable, vehicle, and gaze data\n",
    "3. Put them all together\n",
    "4. Combine them with change points\n",
    "5. Plotting them for some visualization\n",
    "6. Run GMM\n",
    "    - Prepration, finding number of components, adn running GMM\n",
    "7. Taking out times that the participant is out side of the vehicle\n",
    "8. plotting joing distributions\n",
    "9. plotting multivariate change points\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Reading change points \n",
    "import pandas as pd \n",
    "\n",
    "change_point_hr_included = pd.read_csv(\"csv files/change_point_hr_included.csv\")\n",
    "change_point_hr_included[\"diff\"] = change_point_hr_included[\"HR _bcp_mean\"].shift(+1) - change_point_hr_included[\"HR _bcp_mean\"]\n",
    "change_point_hr_included.loc[0,\"diff\"]=0\n",
    "change_point_hr_included[\"group\"] = change_point_hr_included[\"diff\"].ne(0).cumsum()\n",
    "change_point_hr_included[\"group\"] = change_point_hr_included[\"group\"] + 1\n",
    "list_groups=[]\n",
    "for key,group in change_point_hr_included.groupby(\"group\"):\n",
    "    if group[\"diff\"].mean()>0:\n",
    "        group[\"new_group\"] = 0\n",
    "    else:\n",
    "        group[\"new_group\"] = group[\"group\"]\n",
    "    list_groups.append(group)\n",
    "list_groups = pd.concat(list_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.1 Reading all sources of wearable, vehicle, and gaze data\n",
    "\n",
    "#read car's data\n",
    "#reading acc,gyro, and linear acc data, put them together, resample at 100 hz, fill nans and make it a clean dataframe\n",
    "import pandas as pd \n",
    "from tqdm import tqdm\n",
    "\n",
    "sensors = [\"GyroscopeDatum\",\"AccelerometerDatum\",\"LinearAccelerationDatum\"]\n",
    "df_ultimate = []\n",
    "\n",
    "for sensor in sensors:\n",
    "    df_temp = pd.read_csv(\"C:/Users/Arsalan/Desktop/both hands and car/raw/car/\"+\"Smartwatch_\"+sensor+\".csv\",parse_dates=['Timestamp'])\n",
    "    #start_date = \"2020-08-21T23:30:59.154+0000\"\n",
    "    #end_date = \"2020-08-22T02:14:56.307+0000\"\n",
    "    start_date = \"2020-08-23T15:16:11.508+0000\"\n",
    "    end_date = \"2020-08-23T18:22:39.074+0000\"\n",
    "    mask = (df_temp['Timestamp'] > start_date) & (df_temp['Timestamp'] <= end_date)\n",
    "    df_temp = df_temp.loc[mask]\n",
    "    if sensor in [\"GyroscopeDatum\",\"AccelerometerDatum\",\"LinearAccelerationDatum\"]:\n",
    "        df_temp.rename(columns={'X': 'X'+sensor[:4], 'Y': 'Y'+sensor[:4],'Z':'Z'+sensor[:4]}, inplace=True)\n",
    "    df_ultimate.append(df_temp)\n",
    "\n",
    "    \n",
    "df_final = df_ultimate[0]\n",
    "for df in df_ultimate[1:]:\n",
    "    df = df.drop(columns=[\"participantid\"])\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    df_final = df_final.merge(df,on=['Timestamp',\n",
    "                                         'DeviceId'], how='outer')\n",
    "    \n",
    "    \n",
    "df_final = df_final.set_index(\"Timestamp\")\n",
    "df_final = df_final.groupby([\"DeviceId\"]).resample('1000L').mean().ffill().bfill()\n",
    "df_final = df_final.reset_index()\n",
    "df_final[\"magGyro\"] = (df_final[\"XGyro\"]**2 + df_final[\"YGyro\"]**2 + df_final[\"ZGyro\"]**2)**0.5\n",
    "df_final[\"magAcce\"] = (df_final[\"XAcce\"]**2 + df_final[\"YAcce\"]**2 + df_final[\"ZAcce\"]**2)**0.5\n",
    "df_final[\"magLine\"] = (df_final[\"XLine\"]**2 + df_final[\"YLine\"]**2 + df_final[\"ZLine\"]**2)**0.5\n",
    "\n",
    "#keep a copy to not rerun things\n",
    "imu_data_car = df_final.copy()\n",
    "imu_data_car = imu_data_car.set_index(\"Timestamp\")\n",
    "imu_data_car = df_final.copy()\n",
    "imu_data_car = imu_data_car.set_index(\"Timestamp\")\n",
    "imu_data_car = imu_data_car[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.2 Reading all sources of wearable, vehicle, and gaze data\n",
    "#reading acc,gyro, and linear acc data, put them together, resample at 100 hz, fill nans and make it a clean dataframe\n",
    "import pandas as pd \n",
    "from tqdm import tqdm\n",
    "\n",
    "sensors = [\"HeartRateDatum\",\"GyroscopeDatum\",\"AccelerometerDatum\",\"LinearAccelerationDatum\",\"Light\"]\n",
    "df_ultimate = []\n",
    "\n",
    "for sensor in sensors:\n",
    "    df_temp = pd.read_csv(\"C:/Users/Arsalan/Desktop/both hands and car/raw/\"+\"Smartwatch_\"+sensor+\".csv\",parse_dates=['Timestamp'])\n",
    "#     start_date = \"2020-08-21T23:30:59.154+0000\"\n",
    "#     end_date = \"2020-08-22T02:14:56.307+0000\"\n",
    "    start_date = \"2020-08-23T15:16:11.508+0000\"\n",
    "    end_date = \"2020-08-23T18:21:56.074+0000\"\n",
    "    mask = (df_temp['Timestamp'] > start_date) & (df_temp['Timestamp'] <= end_date)\n",
    "    df_temp = df_temp.loc[mask]\n",
    "    if sensor in [\"GyroscopeDatum\",\"AccelerometerDatum\",\"LinearAccelerationDatum\"]:\n",
    "        df_temp.rename(columns={'X': 'X'+sensor[:4]+\"_driver\", 'Y': 'Y'+sensor[:4]+\"_driver\",'Z':'Z'+sensor[:4]+\"_driver\"}, inplace=True)\n",
    "    df_ultimate.append(df_temp)\n",
    "\n",
    "    \n",
    "df_final = df_ultimate[0]\n",
    "for df in df_ultimate[1:]:\n",
    "    df = df.drop(columns=[\"participantid\"])\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    df_final = df_final.merge(df,on=['Timestamp',\n",
    "                                         'DeviceId'], how='outer')\n",
    "    \n",
    "    \n",
    "df_final = df_final.set_index(\"Timestamp\")\n",
    "df_final = df_final.groupby([\"DeviceId\"]).resample('1000L').mean().ffill().bfill()\n",
    "df_final = df_final.reset_index()\n",
    "df_final[\"magGyro_driver\"] = (df_final[\"XGyro_driver\"]**2 + df_final[\"YGyro_driver\"]**2 + df_final[\"ZGyro_driver\"]**2)**0.5\n",
    "df_final[\"magAcce_driver\"] = (df_final[\"XAcce_driver\"]**2 + df_final[\"YAcce_driver\"]**2 + df_final[\"ZAcce_driver\"]**2)**0.5\n",
    "df_final[\"magLine_driver\"] = (df_final[\"XLine_driver\"]**2 + df_final[\"YLine_driver\"]**2 + df_final[\"ZLine_driver\"]**2)**0.5\n",
    "\n",
    "#keep a copy to not rerun things\n",
    "hr_imu_data = df_final.copy()\n",
    "hr_imu_data = hr_imu_data.set_index(\"Timestamp\")\n",
    "hr_imu_data_left=hr_imu_data[hr_imu_data[\"DeviceId\"]==\"f60691a313420a4e\"]\n",
    "hr_imu_data_right=hr_imu_data[hr_imu_data[\"DeviceId\"]==\"39ca51c16b9ec429\"]\n",
    "#imu_data_right = imu_data_right.set_index(\"Timestamp\")\n",
    "#imu_data_left = imu_data_left.set_index(\"Timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.3 Reading all sources of wearable, vehicle, and gaze data\n",
    "#reading gaze data\n",
    "\n",
    "cols = [\" timestamp\",\" confidence\",\" success\",\" gaze_angle_x\",\" gaze_angle_y\",\" p_scale\",\" p_rx\",\" p_ry\",\" p_rz\",\" p_tx\",\" p_ty\",\"video_name\",\"day\" ]\n",
    "gaze = pd.read_csv(\"C:/Users/Arsalan/Desktop/both hands and car/raw/final_gaze.csv\",usecols=cols)\n",
    "\n",
    "gaze[\"time_start\"] = (gaze[\"video_name\"].str[:-7])\n",
    "gaze[\"time_start\"] = pd.to_datetime(gaze[\"time_start\"],format = '%Y%m%d_%H%M%S')\n",
    "gaze[\" timestamp\"] = pd.to_timedelta(gaze[\" timestamp\"],unit = 's')\n",
    "gaze[\"Timestamp\"] = gaze[\"time_start\"] + gaze[\" timestamp\"]\n",
    "gaze[\"mag_gaze\"] = (gaze[\" gaze_angle_x\"]**2 + gaze[\" gaze_angle_y\"]**2)**0.5\n",
    "gaze[\"Timestamp\"] = gaze[\"Timestamp\"] + pd.Timedelta(value=+4,unit='h')\n",
    "# start_date = pd.Timestamp(\"2020-08-21T23:30:59.154+0000\",tz=None)\n",
    "# end_date = pd.Timestamp(\"2020-08-22T02:14:56.307+0000\",tz=None)\n",
    "start_date = pd.Timestamp(\"2020-08-23T15:16:11.508+0000\",tz=None)\n",
    "end_date = pd.Timestamp(\"2020-08-23T18:21:56.074+0000\",tz=None)\n",
    "start_date = start_date.tz_localize(None)\n",
    "end_date = end_date.tz_localize(None)\n",
    "gaze[\"Timestamp\"] = pd.to_datetime(gaze[\"Timestamp\"])  \n",
    "gaze[\"Timestamp\"] = gaze[\"Timestamp\"].dt.tz_localize(None)\n",
    "mask = (gaze[\"Timestamp\"] > start_date) & (gaze[\"Timestamp\"] <= end_date)\n",
    "gaze = gaze.loc[mask]\n",
    "gaze = gaze.set_index(\"Timestamp\")\n",
    "gaze = gaze.resample('1000L').mean().bfill().ffill()\n",
    "gaze = gaze.drop(columns=[' confidence', ' success','day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. put them all together\n",
    "\n",
    "hr_imu_data_right.index = hr_imu_data_right.index.tz_localize(None)\n",
    "imu_data_car.index = imu_data_car.index.tz_localize(None)\n",
    "total_data = pd.concat([gaze,hr_imu_data_right,imu_data_car],axis=1)\n",
    "\n",
    "#4. combining them with change points - copying bcp groups from previous steps\n",
    "total_data = total_data[:-1]\n",
    "#total_data[\"bcp_groups\"] = list_groups[\"new_group\"].values\n",
    "total_data = total_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving a copy\n",
    "total_data.to_csv(\"all_data_coming_back_100L.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#5. Plotting them for some visualization \n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import wasserstein_distance\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "fig1 = make_subplots(rows=9, cols=1, \n",
    "                    shared_xaxes=True,vertical_spacing =0.05)\n",
    "fig1.add_trace(go.Scatter(x=total_data.index, y=total_data[\"HR\"],name= \"HR\",yaxis='y1',line=dict(width=4,color='black')),row=1,col=1)\n",
    "fig1.add_trace(go.Scatter(x=total_data.index, y=total_data[\"magGyro_driver\"],name= \"Magnitude of Gyroscope - Driver\",yaxis='y2',line=dict(width=4,color='red')),row=2,col=1)\n",
    "fig1.add_trace(go.Scatter(x=total_data.index, y=total_data[\"magAcce_driver\"],name= \"Magnitude of Accelerometer - Driver\",yaxis='y3',line=dict(width=4,color='purple')),row=3,col=1)\n",
    "fig1.add_trace(go.Scatter(x=total_data.index, y=total_data[\"magLine_driver\"],name= \"Magnitude of Linear Accelerometer - Driver\",yaxis='y4',line=dict(width=4,color='blue')),row=4,col=1)\n",
    "fig1.add_trace(go.Scatter(x=total_data.index, y=total_data[\"mag_gaze\"],name= \"Magnitude of gaze Angle\",yaxis='y5',line=dict(width=4,color='green')),row=5,col=1)\n",
    "\n",
    "fig1.add_trace(go.Scatter(x=total_data.index, y=total_data[\"magGyro\"],name= \"Magnitude of Gyroscope - Vehicle\",yaxis='y6',line=dict(width=4,color='gray')),row=6,col=1)\n",
    "fig1.add_trace(go.Scatter(x=total_data.index, y=total_data[\"magAcce\"],name= \"Magnitude of Accelerometer - Vehicle\",yaxis='y7',line=dict(width=4,color='goldenrod')),row=7,col=1)\n",
    "fig1.add_trace(go.Scatter(x=total_data.index, y=total_data[\"magLine\"],name= \"Magnitude of Linear Accelerometer - Vehicle\",yaxis='y8',line=dict(width=4,color='pink')),row=8,col=1)\n",
    "\n",
    "fig1.add_trace(go.Scatter(x=total_data.index, y=total_data[\"Light\"],name= \"Light Intensity\",yaxis='y9',line=dict(width=4,color='olive')),row=9,col=1)\n",
    "\n",
    "fig1.update_layout(  \n",
    "    {    \n",
    "        'yaxis':{'title':\"<b>HR (bpm)\",'linecolor':'black'},\n",
    "        'yaxis2':{'title':\"<b>Magnitude\",'linecolor':'black'},\n",
    "        'yaxis3':{'title':\"<b>Magnitude\",'linecolor':'black'},\n",
    "        'yaxis4':{'title':\"<b>Magnitude\",'linecolor':'black'},\n",
    "        'yaxis5':{'title':\"<b>Magnitude\",'linecolor':'black'},\n",
    "        'yaxis6':{'title':\"<b>Magnitude\",'linecolor':'black'},\n",
    "        'yaxis7':{'title':\"<b>Magnitude\",'linecolor':'black'},\n",
    "        'yaxis8':{'title':\"<b>Magnitude\",'linecolor':'black'},\n",
    "        'yaxis9':{'title':\"<b>Intensity (flux)\",'linecolor':'black'},\n",
    "        'xaxis':{'title':\"<b>Time\",'linecolor':'black'},\n",
    "        'xaxis2':{'title':\"<b>Time\",'linecolor':'black'},\n",
    "        'xaxis3':{'title':\"<b>Time\",'linecolor':'black'},\n",
    "        'xaxis4':{'title':\"<b>Time\",'linecolor':'black'},\n",
    "        'xaxis5':{'title':\"<b>Time\",'linecolor':'black'},\n",
    "        'xaxis6':{'title':\"<b>Time\",'linecolor':'black'},\n",
    "        'xaxis7':{'title':\"<b>Time\",'linecolor':'black'},\n",
    "        'xaxis8':{'title':\"<b>Time\",'linecolor':'black'},\n",
    "        'xaxis9':{'title':\"<b>Time\",'linecolor':'black'},\n",
    "        'height':1100,\n",
    "        'width':1100,\n",
    "        'font':dict(size=14),\n",
    "        'paper_bgcolor':'rgba(0,0,0,0)',\n",
    "        'plot_bgcolor':'rgba(0,0,0,0)'\n",
    "        \n",
    "    }\n",
    ")\n",
    "fig1.update_layout(legend=dict(\n",
    "    yanchor=\"top\",\n",
    "    xanchor=\"left\",\n",
    "    \n",
    "))\n",
    "\n",
    "\n",
    "fig1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6.1 prepare GMM \n",
    "#Option 1 :gmm for case study on all data and all features\n",
    "\n",
    "list_of_sensors = ['HR','magGyro_driver', ' gaze_angle_y','HR','XAcce', 'YAcce','XGyro', 'YGyro','magGyro_driver']\n",
    "gmm_dataset = total_data[list_of_sensors]\n",
    "\n",
    "\n",
    "gmm_dataset_mean = gmm_dataset[list_of_sensors].ffill().bfill().rolling(5).mean()\n",
    "\n",
    "gmm_dataset_std = gmm_dataset[list_of_sensors].ffill().bfill().rolling(5).std()\n",
    "\n",
    "\n",
    "gmm_dataset_mean.columns = [c+'_mean' for c in gmm_dataset_mean.columns]\n",
    "gmm_dataset_std .columns = [c+'_std' for c in gmm_dataset_std.columns]\n",
    "\n",
    "gmm_final_dataset = pd.concat([gmm_dataset_mean,gmm_dataset_std, gmm_dataset], axis=1)\n",
    "gmm_final_dataset = gmm_final_dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6.2 prepare GMM\n",
    "#option 2: running gmm only on clusters of change points\n",
    "\n",
    "gmm_prep = total_data.copy()\n",
    "gmm_prep = gmm_prep[gmm_prep[\"bcp_groups\"] != 0]\n",
    "gmm_prep = gmm_prep.groupby(['bcp_groups']).filter(lambda x: len(x) > 7)\n",
    "\n",
    "list_of_sensors = ['magGyro_driver', ' gaze_angle_x','HR', 'YAcce']\n",
    "gmm_dataset = gmm_prep[list_of_sensors]\n",
    "\n",
    "\n",
    "gmm_dataset_mean = gmm_dataset[list_of_sensors].ffill().bfill().rolling(5).mean()\n",
    "\n",
    "gmm_dataset_std = gmm_dataset[list_of_sensors].ffill().bfill().rolling(5).std()\n",
    "\n",
    "\n",
    "gmm_dataset_mean.columns = [c+'_mean' for c in gmm_dataset_mean.columns]\n",
    "gmm_dataset_std .columns = [c+'_std' for c in gmm_dataset_std.columns]\n",
    "\n",
    "gmm_final_dataset = pd.concat([gmm_dataset_mean,gmm_dataset_std, gmm_dataset], axis=1)\n",
    "gmm_final_dataset = gmm_final_dataset.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing features\n",
    "\n",
    "list_of_sensors_new = ['magGyro_driver_mean', ' gaze_angle_x_mean', 'HR_mean', 'HR_std',\n",
    "       'YAcce_std','magGyro_driver', ' gaze_angle_x', 'HR', 'YAcce']\n",
    "X = gmm_final_dataset.drop(columns=list_of_sensors_new)\n",
    "for column in X.columns:\n",
    "    X[column]=(X[column]-X[column].mean())/X[column].std()\n",
    "X = X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_final_dataset.to_csv(\"all_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6.3 get number of components\n",
    "\n",
    "from sklearn import mixture\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "n_components = np.arange(1, 30)\n",
    "models = [mixture.GaussianMixture(n, random_state=0).fit(X)\n",
    "          for n in n_components]\n",
    "\n",
    "plt.plot(n_components, [m.bic(X) for m in models], label='BIC')\n",
    "plt.plot(n_components, [m.aic(X) for m in models], label='AIC')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('n_components');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6.4 GMM running\n",
    "from sklearn import mixture\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "gmm = mixture.GaussianMixture(n_components=6).fit(X)\n",
    "labels = gmm.predict(X)\n",
    "gmm_final_dataset[\"label\"] = labels\n",
    "total_data[\"label\"] = gmm_final_dataset[\"label\"]\n",
    "total_data[\"label\"] = total_data[\"label\"].fillna(value=\"7\")\n",
    "fig = px.scatter(total_data,x=total_data.index,y=\"HR\",color=\"label\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7 taking out times that the participant is out side of the vehicle\n",
    "\n",
    "t1 = pd.Timestamp(\"2020-08-21T23:38:00.000+0000\",tz=None)\n",
    "t1 = t1.tz_localize(None)\n",
    "t2 = pd.Timestamp(\"2020-08-21T23:42:13.000+0000\",tz=None)\n",
    "t2 = t2.tz_localize(None)\n",
    "t3 =  pd.Timestamp(\"2020-08-22T01:09:54.000+0000\",tz=None)\n",
    "t3 = t3.tz_localize(None)\n",
    "t4 = pd.Timestamp(\"2020-08-22T01:28:06.000+0000\",tz=None)\n",
    "t4 = t4.tz_localize(None)\n",
    "\n",
    "gmm_final_dataset = gmm_final_dataset[~(((gmm_final_dataset.index>t1) & (gmm_final_dataset.index<t2)) | \n",
    "                    ((gmm_final_dataset.index>t3) & (gmm_final_dataset.index<t4)))]\n",
    "\n",
    "gmm_final_dataset[\"acc_categorical\"] = np.sign(gmm_final_dataset[\"YAcce_mean\"])\n",
    "gmm_final_dataset[\"acc_categorical\"] = gmm_final_dataset[\"acc_categorical\"].astype('category')\n",
    "gmm_final_dataset.loc[gmm_final_dataset[\"acc_categorical\"] == 1, 'type'] = \"Accelerating\"\n",
    "gmm_final_dataset.loc[gmm_final_dataset[\"acc_categorical\"] == -1, 'type'] = \"Decelarating\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8 plotting joing distributions\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.displot(\n",
    "    gmm_final_dataset,\n",
    "    x=\"HR_mean\", y=\" gaze_angle_x_std\",hue='type'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. plotting multivariate change points\n",
    "\n",
    "import pandas\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import wasserstein_distance\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "change_point_all = pd.read_csv(\"D:/Google Drive/UVA_PhD/Projects/Wearable Projects/Codes/Wearable_Event_detection/csv files/change_point_all_included.csv\")\n",
    "change_point_all[\"sum_of_probs\"] = change_point_all[\"HR_only _bcp_prob\"] +  change_point_all[\"gaze _bcp_prob\"]\n",
    "\n",
    "fig1 = make_subplots(rows=5, cols=1, \n",
    "                    shared_xaxes=True,vertical_spacing =0.05)\n",
    "fig1.add_trace(go.Scatter(x=change_point_all[\"Timestamp\"], y=change_point_all[\"HR\"],\n",
    "                          name= \"HR\",yaxis='y1',line=dict(width=4,color='black')),row=1,col=1)\n",
    "fig1.add_trace(go.Scatter(x=change_point_all[\"Timestamp\"], y=change_point_all[\"HR_only _bcp_mean\"],\n",
    "                          name= \"HR_BCP_Mean\",yaxis='y1',line=dict(width=2,color='red')),row=1,col=1)\n",
    "\n",
    "fig1.add_trace(go.Scatter(x=change_point_all[\"Timestamp\"], y=change_point_all[\"HR_only _bcp_prob\"],\n",
    "                          name= \"HR_BCP_prob\",yaxis='y1',line=dict(width=2,color='peru')),row=2,col=1)\n",
    "\n",
    "fig1.add_trace(go.Scatter(x=change_point_all[\"Timestamp\"], y=change_point_all[\"gaze_angle_x\"],\n",
    "                          name= \"Gaze - Horizontal\",yaxis='y1',line=dict(width=4,color='blue')),row=3,col=1)\n",
    "fig1.add_trace(go.Scatter(x=change_point_all[\"Timestamp\"], y=change_point_all['gaze _bcp_mean'],\n",
    "                          name= \"Gaze_BCP_Mean\",yaxis='y1',line=dict(width=2,color='purple')),row=3,col=1)\n",
    "\n",
    "fig1.add_trace(go.Scatter(x=change_point_all[\"Timestamp\"], y=change_point_all['gaze _bcp_prob'],\n",
    "                          name= \"Gaze_BCP_Prob\",yaxis='y1',line=dict(width=2,color='orange')),row=4,col=1)\n",
    "\n",
    "fig1.add_trace(go.Scatter(x=change_point_all[\"Timestamp\"], y=change_point_all['sum_of_probs'],\n",
    "                          name= \"Sum of probabilities\",yaxis='y1',line=dict(width=2,color='green')),row=5,col=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig1.update_layout(  \n",
    "    {    \n",
    "        'yaxis':{'title':\"<b>HR (bpm)\",'linecolor':'black'},\n",
    "        'yaxis2':{'title':\"<b>HR <br>(probability)\",'linecolor':'black'},\n",
    "        'yaxis3':{'title':\"<b>Gaze angle <br>in horizontal\",'linecolor':'black'},\n",
    "        'yaxis4':{'title':\"<b>Gaze angle <br>(probability)\",'linecolor':'black'},\n",
    "        'yaxis5':{'title':\"<b>Probability - <br>gaze and HR\",'linecolor':'black'},\n",
    "        'xaxis5':{'title':\"<b>Time\",'linecolor':'black'},\n",
    "        'height':1100,\n",
    "        'width':1100,\n",
    "        'font':dict(size=10),\n",
    "        'paper_bgcolor':'rgba(0,0,0,0)',\n",
    "        'plot_bgcolor':'rgba(0,0,0,0)'\n",
    "        \n",
    "    }\n",
    ")\n",
    "fig1.update_layout(legend=dict(\n",
    "    yanchor=\"top\",\n",
    "    xanchor=\"left\",\n",
    "    \n",
    "))\n",
    "\n",
    "fig1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are a couple of preprations that needs to be done for analysis in R. You probably do not need this, as you have performed it once. Just keeping it here for now. \n",
    "1. Loading Data for Arash\n",
    "2. Adding Annotations for Arash\n",
    "3. Loading Data for everyone else and resampling it\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Loading Data\n",
    "\n",
    "#change point detection\n",
    "#Prepration for analysis in R\n",
    "\n",
    "import pandas as pd \n",
    "from tqdm import tqdm\n",
    "\n",
    "sensors = [\"HeartRateDatum\",\"Light\",\"GyroscopeDatum\",\"AccelerometerDatum\",\"LinearAccelerationDatum\"]\n",
    "df_ultimate = []\n",
    "\n",
    "for sensor in sensors:\n",
    "    df_temp = pd.read_csv(\"C:/Users/Arsalan/Desktop/both hands and car/raw/\"+\"Smartwatch_\"+sensor+\".csv\",parse_dates=['Timestamp'])\n",
    "    start_date = \"2020-08-21T23:03:59.154+0000\"\n",
    "    end_date = \"2020-08-22T01:02:34.971+0000\"\n",
    "    mask = (df_temp['Timestamp'] > start_date) & (df_temp['Timestamp'] <= end_date)\n",
    "    df_temp = df_temp.loc[mask]\n",
    "    if sensor in [\"GyroscopeDatum\",\"AccelerometerDatum\",\"LinearAccelerationDatum\"]:\n",
    "        df_temp.rename(columns={'X': 'X'+sensor[:4], 'Y': 'Y'+sensor[:4],'Z':'Z'+sensor[:4]}, inplace=True)\n",
    "    df_ultimate.append(df_temp)\n",
    "\n",
    "df_final = df_ultimate[0]\n",
    "for df in df_ultimate[1:]:\n",
    "    df = df.drop(columns=[\"participantid\"])\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    df_final = df_final.merge(df,on=['Timestamp',\n",
    "                                         'DeviceId'], how='outer')\n",
    "    \n",
    "that_fucking_list = []\n",
    "for key,group in df_final.groupby(\"DeviceId\"):\n",
    "    print(key)\n",
    "    df_final = group\n",
    "    df_final = df_final.set_index('Timestamp')\n",
    "    df_final = df_final.resample('10L').mean()\n",
    "    df_final = df_final.reset_index()\n",
    "    df_final = df_final.sort_values(by=\"Timestamp\")\n",
    "    df_final = df_final.ffill().bfill()\n",
    "    df_final[\"DeviceId\"] = key\n",
    "    that_fucking_list.append(df_final)\n",
    "\n",
    "target_file = pd.concat(that_fucking_list,axis=0)\n",
    "features = [ 'HR', 'Light', 'XGyro', 'YGyro', 'ZGyro', 'XAcce', 'YAcce',\n",
    "       'ZAcce', 'XLine', 'YLine', 'ZLine']\n",
    "for x in features:\n",
    "    #print(x)\n",
    "    target_file[x] = target_file[x].ffill().bfill()\n",
    "\n",
    "target_file[\"magGyro\"] = target_file[\"XGyro\"]**2 + target_file[\"YGyro\"]**2 + target_file[\"ZGyro\"]**2\n",
    "target_file[\"magAcce\"] = target_file[\"XAcce\"]**2 + target_file[\"YAcce\"]**2 + target_file[\"ZAcce\"]**2\n",
    "target_file[\"magLine\"] = target_file[\"XLine\"]**2 + target_file[\"YLine\"]**2 + target_file[\"ZLine\"]**2\n",
    "\n",
    "features = [ 'HR', 'Light', 'XGyro', 'YGyro', 'ZGyro', 'XAcce', 'YAcce','ZAcce', 'XLine', 'YLine', 'ZLine',\"magGyro\",\"magLine\",\"magAcce\" ]\n",
    "final_groups = []\n",
    "\n",
    "for key,group in target_file.groupby([\"DeviceId\"]):\n",
    "    print(group.shape)\n",
    "    group = group.sort_values(by=\"Timestamp\")\n",
    "    group = group.reset_index()\n",
    "    group_mean = group[features].ffill().bfill().rolling(5,min_periods=0).mean()\n",
    "    group_std = group[features].ffill().bfill().rolling(5,min_periods=0).std()\n",
    "    group_mean.columns = [c+'_mean' for c in group_mean.columns]\n",
    "    group_std.columns = [c+'_std' for c in group_std.columns]\n",
    "    group_overall = pd.concat([group,group_mean,group_std],axis=1)\n",
    "    group_overall[\"DeviceId\"] = key\n",
    "    final_groups.append(group_overall)\n",
    "    \n",
    "final_groups = pd.concat(final_groups)\n",
    "final_groups = final_groups.dropna(how=\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Adding annotations\n",
    "\n",
    "import pandas as pd \n",
    "import os\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "def get_sec(time_str):\n",
    "    \"\"\"Get Seconds from time.\"\"\"\n",
    "    #print(time_str)\n",
    "    h, m, s = time_str.split(':')\n",
    "    return int(h) * 3600 + int(m) * 60 + int(s)\n",
    "\n",
    "\n",
    "def time_transfer(dateandtime,video_name):\n",
    "    base_time = dt.datetime.strptime(video_name[:4]+\"-\"+video_name[4:6]+\"-\"+video_name[6:8]+\"T\"+video_name.split(\"_\")[1][:2]+\":\"+video_name.split(\"_\")[1][2:4]+\":\"+video_name.split(\"_\")[1][4:6]+\".000\",\"%Y-%m-%dT%H:%M:%S.%f\")-dt.timedelta(hours=4)#.microsecond\n",
    "    item_time = dt.datetime.strptime(dateandtime.split(\"+\")[0],\"%Y-%m-%dT%H:%M:%S.%f\")\n",
    "    timestamp = ((item_time-base_time).seconds+(item_time-base_time).microseconds/1000000)-36000\n",
    "    return timestamp\n",
    "\n",
    "\n",
    "\n",
    "gt = pd.read_csv(\"I:/Phase 1/9/Video/08232020/Folder arash.csv\")\n",
    "gt = gt.dropna(how='all')\n",
    "gt = gt[~gt[\"Event\"].str.startswith(\"driving\")]\n",
    "gt[\"time_start\"] = (gt[\"Video\"].str[:-7])\n",
    "gt[\"time_start\"] = pd.to_datetime(gt[\"time_start\"],format = '%Y%m%d_%H%M%S')\n",
    "gt[\"Timestamp Begin\"] = gt[\"Timestamp Begin\"].apply(get_sec)\n",
    "gt[\"Timestamp End\"] = gt[\"Timestamp End\"].apply(get_sec)\n",
    "gt[\"Timestamp Begin\"] = pd.to_timedelta(gt[\"Timestamp Begin\"],unit='s')\n",
    "gt[\"Timestamp End\"] = pd.to_timedelta(gt[\"Timestamp End\"],unit='s')\n",
    "gt[\"current_time_start\"] = gt[\"time_start\"] + gt[\"Timestamp Begin\"] \n",
    "gt[\"current_time_start\"] = gt[\"current_time_start\"].dt.tz_localize(None)\n",
    "gt[\"current_time_end\"] = gt[\"time_start\"] + gt[\"Timestamp End\"] \n",
    "gt[\"current_time_end\"] = gt[\"current_time_end\"].dt.tz_localize(None)\n",
    "\n",
    "gt_inside = gt[gt[\"Video\"].str.endswith(\"R.mp4\")]\n",
    "gt_outside = gt = gt[gt[\"Video\"].str.endswith(\"F.mp4\")]\n",
    "target_file = final_groups.copy()\n",
    "target_file[\"Timestamp_new\"] = pd.to_datetime(target_file[\"Timestamp\"]) + pd.Timedelta(value=-4,unit='h')\n",
    "target_file[\"Timestamp_new\"] = target_file[\"Timestamp_new\"].dt.tz_localize(None)\n",
    "target_file[\"event_inside\"] =\"none\"\n",
    "target_file[\"event_outside\"] =\"none\"\n",
    "target_file[\"timestamp_inside\"] = \"none\"\n",
    "target_file[\"timestamp_outside\"] = \"none\"\n",
    "target_file[\"source_inside\"] = \"none\"\n",
    "target_file[\"source_outside\"] = \"none\"\n",
    "for index,row in gt_inside.iterrows():\n",
    "    target_file[\"event_inside\"][(target_file['Timestamp_new']>(row['current_time_start'])) \n",
    "                                & (target_file['Timestamp_new']<(row['current_time_end']))] = row[\"Event\"]\n",
    "    target_file[\"timestamp_inside\"][(target_file['Timestamp_new']>(row['current_time_start'])) \n",
    "                                & (target_file['Timestamp_new']<(row['current_time_end']))] = row[\"Timestamp Begin\"]\n",
    "    target_file[\"source_inside\"][(target_file['Timestamp_new']>(row['current_time_start'])) \n",
    "                                & (target_file['Timestamp_new']<(row['current_time_end']))] = row[\"Video\"]\n",
    "for index,row in gt_outside.iterrows():\n",
    "    target_file[\"event_outside\"][(target_file['Timestamp_new']>(row['current_time_start'])) \n",
    "                                & (target_file['Timestamp_new']<(row['current_time_end']))] = row[\"Event\"]\n",
    "    target_file[\"timestamp_outside\"][(target_file['Timestamp_new']>(row['current_time_start'])) \n",
    "                                & (target_file['Timestamp_new']<(row['current_time_end']))] = row[\"Timestamp Begin\"]\n",
    "    target_file[\"source_outside\"][(target_file['Timestamp_new']>(row['current_time_start'])) \n",
    "                                & (target_file['Timestamp_new']<(row['current_time_end']))] = row[\"Video\"]\n",
    "target_file.sort_values(by=\"Timestamp\")\n",
    "target_file.to_csv(\"both_hand_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. laoding data for everyone and resampling\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "HR = pd.read_csv(\"D:/Google Drive/UVA_PhD/Projects/Wearable Projects/Sample data/HR.csv\",parse_dates=[\"Timestamp\"])\n",
    "HR = HR.drop(columns = ['Unnamed: 0', 'Unnamed: 0.1'])\n",
    "HR = HR.set_index(\"Timestamp\")\n",
    "HR = HR.groupby([\"source\"]).resample('1000L').mean().ffill().bfill()\n",
    "HR = HR.reset_index()\n",
    "HR = HR.to_csv(\"all_participants_HR_resampled_for_R.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. plotting all participant data\n",
    "\n",
    "import pandas as pd \n",
    "from tqdm import tqdm\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import wasserstein_distance\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "bcp_inc_all = pd.read_csv(\"D:/Google Drive/UVA_PhD/Projects/Wearable Projects/Codes/Wearable_Event_detection/csv files/change_point_hr_included_all_participants.csv\")\n",
    "bcp_inc_all = bcp_inc_all.drop(columns = [\"Unnamed: 0\",\"X\"])\n",
    "\n",
    "#bcp_inc_all =bcp_inc_all.set_index(\"Timestamp\")\n",
    "for val in bcp_inc_all.source.unique():\n",
    "    temp = bcp_inc_all[bcp_inc_all[\"source\"] == val]\n",
    "    print(val)\n",
    "    fig1 = make_subplots(rows=3, cols=1, \n",
    "                        shared_xaxes=True,vertical_spacing =0.05)\n",
    "    fig1.add_trace(go.Scatter(x=temp.index, y=temp[\"HR\"],name= \"HR\",yaxis='y2',line=dict(width=4,color='black')),row=1,col=1)\n",
    "    fig1.add_trace(go.Scatter(x=temp.index, y=temp[\"HR _bcp_mean\"],name= \"HR - mean\",yaxis='y2',line=dict(width=4,color='blue')),row=2,col=1)\n",
    "    fig1.add_trace(go.Scatter(x=temp.index, y=temp[\"HR _bcp_prob\"],name= \"BCP - probability\",line=dict(width=4,color='red')),row=3,col=1)\n",
    "\n",
    "    fig1.update_layout(    \n",
    "        {    \n",
    "            'yaxis':{'dtick': 30,'title':\"<b>HR (bpm)\",'linecolor':'black'},\n",
    "            'yaxis2':{'dtick': 30,'title':\"<b>HR (bpm)\",'linecolor':'black'},\n",
    "            'yaxis3':{'range': [0, 1], 'dtick': 0.2,'title':'<b>Pr','linecolor':'black'},\n",
    "            'xaxis3':{'title':\"<b>Time\",'linecolor':'black'},\n",
    "            'height':600,\n",
    "            'width':1200,\n",
    "            'font':dict(size=14),\n",
    "            'paper_bgcolor':'rgba(0,0,0,0)',\n",
    "            'plot_bgcolor':'rgba(0,0,0,0)'\n",
    "        }\n",
    "    )\n",
    "\n",
    "    fig1.show()\n",
    "    input(\"Press Enter to continue...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. count plot of all instances\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "#sns.set(font_scale=2.5)\n",
    "list_of_bcp = pd.read_csv(\"D:/Google Drive/UVA_BRAIn_Lab/Arash/Papers/IEEE ACCESS - Dataset Paper/all_peaks_csv.csv\")\n",
    "a4_dims = (11.7, 11.7)\n",
    "fig, ax = pyplot.subplots(figsize=a4_dims)\n",
    "ax = sns.countplot(ax=ax,y=\"Category\", data=list_of_bcp)\n",
    "ax.set_xlabel(\"Number of Instances\",fontsize=30)\n",
    "ax.set_ylabel(\"Category\",fontsize=30)\n",
    "ax.tick_params(labelsize=20)\n",
    "sns.set_style(\"white\")\n",
    "ax.figure.savefig(\"count.png\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here you have to go and perform the analysis in R. Once you are done, you will get a csv from R and will bring it back here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finished BCP analysis in R\n",
    "#reading and plotting them here because why not?\n",
    "import pandas as pd \n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "bcp_inc = pd.read_csv(\"change_point_included_all.csv\")\n",
    "bcp_inc[\"event_inside\"][bcp_inc[\"event_inside\"] !=\"working with phone\"] = \"none\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualization Module \n",
    "\n",
    "devId_vals = bcp_inc[\"DeviceId\"].unique()\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "dev_dic = {\"f60691a313420a4e\":\"left\" , \"39ca51c16b9ec429\":\"right\"}\n",
    "\n",
    "feats = [\"magGyro\",\"magAcce\",\"magLine\",\"HR\",\"Light\"]\n",
    "fig1 = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "for val in feats:\n",
    "    bcp_inc[val] = (bcp_inc[val]-bcp_inc[val].min())/(bcp_inc[val].max()-bcp_inc[val].min())\n",
    "\n",
    "for id in devId_vals:\n",
    "    df_temp = bcp_inc[bcp_inc[\"DeviceId\"]==id]\n",
    "    fig1.add_trace(\n",
    "        go.Scatter(x=df_temp[\"Timestamp\"], y=df_temp[\"magGyro\"], name=\"magGyro - \" + dev_dic[id]),\n",
    "        secondary_y=False,\n",
    "    )\n",
    "    fig1.add_trace(\n",
    "        go.Scatter(x=df_temp[\"Timestamp\"], y=df_temp[\"magAcce\"], name=\"magAcce - \"+ dev_dic[id]),\n",
    "        secondary_y=False,\n",
    "    )\n",
    "    fig1.add_trace(\n",
    "        go.Scatter(x=df_temp[\"Timestamp\"], y=df_temp[\"magLine\"], name=\"magLine - \"+ dev_dic[id]),\n",
    "        secondary_y=False,\n",
    "    )\n",
    "    fig1.add_trace(\n",
    "        go.Scatter(x=df_temp[\"Timestamp\"], y=df_temp[\"HR\"], name=\"HR - \"+ dev_dic[id]),\n",
    "        secondary_y=False,\n",
    "    )\n",
    "    fig1.add_trace(\n",
    "        go.Scatter(x=df_temp[\"Timestamp\"], y=df_temp[\"Light\"], name=\"Light - \"+ dev_dic[id]),\n",
    "        secondary_y=False,\n",
    "    )\n",
    "    fig1.add_trace(\n",
    "        go.Scatter(x=df_temp[\"Timestamp\"], y=df_temp[\"XGyro\"], name=\"XGyro - \"+ dev_dic[id]),\n",
    "        secondary_y=False,\n",
    "    )\n",
    "    fig1.add_trace(\n",
    "        go.Scatter(x=df_temp[\"Timestamp\"], y=df_temp[\"YGyro\"], name=\"YGyro - \"+ dev_dic[id]),\n",
    "        secondary_y=False,\n",
    "    )\n",
    "    fig1.add_trace(\n",
    "        go.Scatter(x=df_temp[\"Timestamp\"], y=df_temp[\"ZGyro\"], name=\"ZGyro - \"+ dev_dic[id]),\n",
    "        secondary_y=False,\n",
    "    )\n",
    "    fig1.add_trace(\n",
    "        go.Scatter(x=df_temp[\"Timestamp\"], y=df_temp[\"XAcce\"], name=\"XAcc - \"+ dev_dic[id]),\n",
    "        secondary_y=False,\n",
    "    )\n",
    "    fig1.add_trace(\n",
    "        go.Scatter(x=df_temp[\"Timestamp\"], y=df_temp[\"YAcce\"], name=\"YAcc - \"+ dev_dic[id]),\n",
    "        secondary_y=False,\n",
    "    )\n",
    "    fig1.add_trace(\n",
    "        go.Scatter(x=df_temp[\"Timestamp\"], y=df_temp[\"ZAcce\"], name=\"ZAcc - \"+ dev_dic[id]),\n",
    "        secondary_y=False,\n",
    "    )\n",
    "    fig1.add_trace(\n",
    "        go.Scatter(x=df_temp[\"Timestamp\"], y=df_temp[\"event_inside\"], name=\"inside events - \"+ dev_dic[id]),\n",
    "        secondary_y=True,\n",
    "    )\n",
    "    fig1.update_layout(legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"bottom\",\n",
    "        y=1.02,\n",
    "        xanchor=\"right\",\n",
    "        x=1\n",
    "    ))\n",
    "fig1.update_xaxes(title_text=\"Time\")\n",
    "fig1.update_yaxes(title_text=\"Raw readings\", secondary_y=False)\n",
    "fig1.update_yaxes(title_text=\"Inside Events\", secondary_y=True)\n",
    "\n",
    "fig1.show()\n",
    "\n",
    "devId_vals = bcp_inc[\"DeviceId\"].unique()\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "dev_dic = {\"f60691a313420a4e\":\"left\" , \"39ca51c16b9ec429\":\"right\"}\n",
    "for id in devId_vals:\n",
    "    df_temp = bcp_inc[bcp_inc[\"DeviceId\"]==id]\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df_temp[\"Timestamp\"], y=df_temp[\"magGyro _bcp_prob\"], name=\"magGyro prob - \" + dev_dic[id]),\n",
    "        secondary_y=False,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df_temp[\"Timestamp\"], y=df_temp[\"magAcce _bcp_prob\"], name=\"magAcce prob - \"+ dev_dic[id]),\n",
    "        secondary_y=False,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df_temp[\"Timestamp\"], y=df_temp[\"magLine _bcp_prob\"], name=\"magLine prob - \"+ dev_dic[id]),\n",
    "        secondary_y=False,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df_temp[\"Timestamp\"], y=df_temp[\"HR _bcp_prob\"], name=\"HR prob - \"+ dev_dic[id]),\n",
    "        secondary_y=False,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df_temp[\"Timestamp\"], y=df_temp[\"Light _bcp_prob\"], name=\"Light prob - \"+ dev_dic[id]),\n",
    "        secondary_y=False,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df_temp[\"Timestamp\"], y=df_temp[\"inside_events\"], name=\"inside events - \"+ dev_dic[id]),\n",
    "        secondary_y=True,\n",
    "    )\n",
    "    fig.update_layout(legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"bottom\",\n",
    "        y=1.02,\n",
    "        xanchor=\"right\",\n",
    "        x=1\n",
    "    ))\n",
    "fig.update_xaxes(title_text=\"Time\")\n",
    "fig.update_yaxes(title_text=\"Bayesian Change Point Probability\", secondary_y=False)\n",
    "fig.update_yaxes(title_text=\"Outside Events\", secondary_y=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
